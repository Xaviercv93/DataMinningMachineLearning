{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 16 GPT: Generative Pre-trained Transformer\n",
        "\n",
        "GPT is a model and approach developed by OpenAI. It is primarily known for its capabilities in generating coherent and contextually relevant text over long passages.\n",
        "\n",
        "* Architecture: GPT is based on the Transformer architecture. Unlike some other models that use both an encoder and a decoder, GPT exclusively utilizes the decoder part of the Transformer for its tasks.\n",
        "* Pre-training and Fine-tuning:\n",
        "    - Pre-training: GPT is first pre-trained on a large corpus of text (like books, articles, websites, etc.). During this phase, it learns to predict the next word in a sentence. This process enables the model to learn grammar, facts about the world, reasoning abilities, and even some level of common sense.\n",
        "    - Fine-tuning: After pre-training, the model can be fine-tuned on a specific task, such as translation, question-answering, or summarization, using a smaller, task-specific dataset.\n",
        "\n",
        "* Autoregressive Nature: GPT generates text in an autoregressive manner. This means it produces one word at a time and uses what it's generated so far as a context to generate the next word.\n",
        "\n",
        "#### Key Features:\n",
        "\n",
        "* Generative Abilities: As the name suggests, GPT excels at generating text. It can produce text that is often indistinguishable from what a human might write.\n",
        "* Few-Shot Learning: Introduced with GPT-3, this capability allows the model to perform tasks even when provided with very few examples (sometimes as few as one). By just specifying a task in natural language, GPT-3 can often understand and perform the task without explicit fine-tuning.\n",
        "* Versatility: Unlike many models that are trained for a specific task, GPT models, especially GPT-3, are versatile and can handle a wide range of tasks without task-specific training. This includes writing essays, answering questions, creating poetry, generating code, and much more.\n",
        "\n",
        "#### Versions:\n",
        "\n",
        "* GPT: The original model introduced by OpenAI.\n",
        "\n",
        "* GPT-2: A larger and more powerful version that garnered significant attention due to its impressive text generation capabilities. OpenAI initially withheld the fully-trained model due to concerns about misuse, but later released it given the broader community's responsible usage.\n",
        "\n",
        "* GPT-3: The third iteration with 175 billion parameters, making it one of the largest models ever created. It introduced the concept of few-shot and zero-shot learning, further advancing the state-of-the-art in various NLP tasks."
      ],
      "metadata": {
        "id": "hs7YZaHEObS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Exploring Creative Writing with GPT\n",
        "\n",
        "Your task is to use OpenAI's GPT model to generate creative content. You'll explore various prompts and settings to see how GPT responds and creates different outputs."
      ],
      "metadata": {
        "id": "mjQAOFuEObTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load GPT-2 Model and Tokenizer. GPT-2 is freely available in Hugging Face's model hub and is still highly effective.**"
      ],
      "metadata": {
        "id": "uuGb7nntObTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T01:39:41.085605Z",
          "iopub.execute_input": "2023-08-24T01:39:41.086393Z",
          "iopub.status.idle": "2023-08-24T01:39:56.368394Z",
          "shell.execute_reply.started": "2023-08-24T01:39:41.086341Z",
          "shell.execute_reply": "2023-08-24T01:39:56.366951Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzB9Gok2ObTC",
        "outputId": "7317fa0a-bc72-4ae4-be94-f9f0272502f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model_name = 'gpt2-medium'  # You can start with 'gpt2' (smaller) and then experiment with larger models\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T01:40:02.992402Z",
          "iopub.execute_input": "2023-08-24T01:40:02.992859Z",
          "iopub.status.idle": "2023-08-24T01:40:30.892259Z",
          "shell.execute_reply.started": "2023-08-24T01:40:02.992818Z",
          "shell.execute_reply": "2023-08-24T01:40:30.891050Z"
        },
        "trusted": true,
        "id": "0JCbkl-wObTD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Creative Content Function**\n",
        "\n",
        "El parámetro temperature controla la creatividad y variabilidad de la generación de texto.\n",
        "\n",
        "Con temperature=1.0 (valor por defecto), se conserva la distribución de probabilidad original del modelo. Esto produce una salida más conservadora y probable.\n",
        "\n",
        "Si no se especifica temperature, por defecto toma el valor 0.7. Esto genera una salida más determinista y menos creativa.\n",
        "\n"
      ],
      "metadata": {
        "id": "OU4MgVnWObTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_creative_content(prompt, max_length=150, temperature=1.0):\n",
        "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
        "\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    '''# Generate text\n",
        "    #output = model.generate(input_ids, max_length=max_length, temperature=temperature,\n",
        "                            pad_token_id=tokenizer.eos_token_id)\n",
        "    '''\n",
        "    output = model.generate(input_ids,\n",
        "                            max_length=max_length,\n",
        "                            temperature=temperature,\n",
        "                            pad_token_id=tokenizer.eos_token_id,\n",
        "                            do_sample=True,\n",
        "                            top_k=50,\n",
        "                            top_p=0.95,\n",
        "                            no_repeat_ngram_size=2)\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-08-24T01:40:43.647649Z",
          "iopub.execute_input": "2023-08-24T01:40:43.648928Z",
          "iopub.status.idle": "2023-08-24T01:40:43.656813Z",
          "shell.execute_reply.started": "2023-08-24T01:40:43.648880Z",
          "shell.execute_reply": "2023-08-24T01:40:43.655469Z"
        },
        "trusted": true,
        "id": "eWyHV-IaObTD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment:\n",
        "**Use various prompts and observe GPT's creative capabilities.\n",
        "Change parameters like *max_length* and *temperature* to see their impact. (Note: A higher temperature value makes output more random, while a lower value makes it more deterministic.)**"
      ],
      "metadata": {
        "id": "_IK0Y7qbObTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "  \"Érase una vez, en un reino muy lejano,\",\n",
        "  \"En un futuro distópico, donde la IA gobierna el mundo,\",\n",
        "  \"El último dinosaurio en la Tierra no era como los demás. Éste\",\n",
        "  \"En las profundidades del océano, una civilización secreta\"\n",
        "]\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(generate_creative_content(prompt))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-08-24T01:41:00.065946Z",
          "iopub.execute_input": "2023-08-24T01:41:00.066348Z",
          "iopub.status.idle": "2023-08-24T01:41:54.569183Z",
          "shell.execute_reply.started": "2023-08-24T01:41:00.066318Z",
          "shell.execute_reply": "2023-08-24T01:41:54.568004Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07mp0WwuObTD",
        "outputId": "92af4382-fafa-485e-f6a0-b73726945a67"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Érase una vez, en un reino muy lejano,\n",
            " por lo que yo me siente, me un viejo diferente para lo comentarios, afectivo hombre.\n",
            "\n",
            "El más de la veza, para aquí el último con un cara de mejor, que me toda el año, así, es que parece mi dio en mi santa para me despuerso de vista de las fierro, poder un área, con lo tudo, qué tú los métores. (¿Cómo es uno, señor?!)\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: En un futuro distópico, donde la IA gobierna el mundo,\n",
            " cómo lo siento no se le estarelo. Esse eso es una fuerza de un área, é que lo tienen que no le ha bló las han ha bien esos que hocative un esa. É que los comienzos que bientos ser vies de su su casa, según el trabajo de la fuente. Si no cambio se vinculado a diferentes sonos, porque con su familia que un poco se ha está si se descansando esté le �\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: El último dinosaurio en la Tierra no era como los demás. Éste\n",
            " hacerla puede en los formos del trastro de Pueblo de Cozumel en Mexico, que están que lo largo que habían este eso, esto á las cadaquí más que me parece la forma, élle donde unos formas no pagar a este verdad. El difícil nada que se han que por los verdaderes es aseguró suficiente para criollo, quiere habría el entender desde nascualiza el tiempo\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: En las profundidades del océano, una civilización secreta\n",
            " que la gente de la libertad contra el tratamiento. La gatía estará para el nuevo mundo de siete que te llevaría la juegos de los métodos que puede está olvidade de este oportunidad en España o la primera comunista y esta bajo las nubes de las que señor alguna en la escenario de última cerca.\n",
            "\n",
            "En la bajada de Espana, lo sintuario, esto cuando la\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Vamos a generar con diferentes configuraciones para eso vamos a cambiar max_length=250, temperature=2.0 en la primera configuracion.**"
      ],
      "metadata": {
        "id": "s-kohQXFObTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_creative_content(prompt, max_length=250, temperature=2.0):\n",
        "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
        "\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text\n",
        "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text\n",
        "###########################\n",
        "prompts = [\n",
        "    \"Once upon a time, in a kingdom far away,\",\n",
        "    \"In a dystopian future, where AI rules the world,\",\n",
        "    \"The last dinosaur on Earth was not like the others. It\",\n",
        "    \"Deep beneath the ocean waves, a secret civilization\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(generate_creative_content(prompt))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T01:49:11.248075Z",
          "iopub.execute_input": "2023-08-24T01:49:11.248552Z",
          "iopub.status.idle": "2023-08-24T01:50:47.311666Z",
          "shell.execute_reply.started": "2023-08-24T01:49:11.248512Z",
          "shell.execute_reply": "2023-08-24T01:50:47.310506Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcmcVko0ObTE",
        "outputId": "93b059a5-c2e1-4114-9361-669ca1e959d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Once upon a time, in a kingdom far away,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `2.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " there lived a king who was a great warrior. He was a great warrior, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: In a dystopian future, where AI rules the world,\n",
            " the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: The last dinosaur on Earth was not like the others. It\n",
            " was a giant, bipedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadruped\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: Deep beneath the ocean waves, a secret civilization\n",
            " has been building a vast network of underground tunnels. The tunnels are filled with powerful weapons and technology, and are guarded by powerful creatures.\n",
            "\n",
            "The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel. The player is tasked with finding a way to infiltrate the Brotherhood's underground network, and to stop the Brotherhood from destroying the world.\n",
            "\n",
            "The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel. The player is tasked with finding a way to infiltrate the Brotherhood's underground network, and to stop the Brotherhood from destroying the world. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3,\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Vamos con otra configuracion en este caso max_length=300 con una temperature=3.0, esta es la segunda configuracion**"
      ],
      "metadata": {
        "id": "mM66DsO0ObTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_creative_content(prompt, max_length=300, temperature=3.0):\n",
        "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
        "\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text\n",
        "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text\n",
        "###########################\n",
        "prompts = [\n",
        "    \"Once upon a time, in a kingdom far away,\",\n",
        "    \"In a dystopian future, where AI rules the world,\",\n",
        "    \"The last dinosaur on Earth was not like the others. It\",\n",
        "    \"Deep beneath the ocean waves, a secret civilization\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(generate_creative_content(prompt))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T01:51:28.770834Z",
          "iopub.execute_input": "2023-08-24T01:51:28.771242Z",
          "iopub.status.idle": "2023-08-24T01:53:24.026132Z",
          "shell.execute_reply.started": "2023-08-24T01:51:28.771207Z",
          "shell.execute_reply": "2023-08-24T01:53:24.024900Z"
        },
        "trusted": true,
        "id": "eqjt41vrObTE",
        "outputId": "38b13ea1-68e1-4c65-9de8-4c527c1f332c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Prompt: Once upon a time, in a kingdom far away,\n there lived a king who was a great warrior. He was a great warrior, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king,\n\n--------------------------------------------------\n\nPrompt: In a dystopian future, where AI rules the world,\n the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n\nThe game is set in a dystopian future where AI rules the world,\n\n--------------------------------------------------\n\nPrompt: The last dinosaur on Earth was not like the others. It\n was a giant, bipedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal,\n\n--------------------------------------------------\n\nPrompt: Deep beneath the ocean waves, a secret civilization\n has been building a vast network of underground tunnels. The tunnels are filled with powerful weapons and technology, and are guarded by powerful creatures.\n\nThe game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel. The player is tasked with finding a way to infiltrate the Brotherhood's underground network, and to stop the Brotherhood from destroying the world.\n\nThe game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel. The player is tasked with finding a way to infiltrate the Brotherhood's underground network, and to stop the Brotherhood from destroying the world. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set\n\n--------------------------------------------------\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion and Analysis:**\n"
      ],
      "metadata": {
        "id": "HiHEEBIiObTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Analyze the quality of the generated text: coherence, relevancy, and creativity.**"
      ],
      "metadata": {
        "id": "VR6rSYLYObTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primera Indicación: La coherencia del texto generado es escasa y se vuelve repetitivo y sin sentido. El texto comienza con una premisa coherente pero se desvanece en frases repetidas. La relevancia disminuye a medida que avanza el texto. No hay creatividad ya que el modelo parece estar reciclando las mismas frases.\n",
        "\n",
        "Segunda Indicación: La coherencia se mantiene y la relevancia inicial está presente con el concepto de sobrevivir como un cíborg. Sin embargo, el texto pierde rápidamente coherencia al empezar a repetirse y la relevancia disminuye. Hay creatividad limitada ya que el modelo se adhiere a la misma idea sin expandirla.\n",
        "\n",
        "Tercera Indicación: El texto generado carece de coherencia desde el principio y se vuelve sin sentido con frases repetidas. Se pierde la relevancia con respecto a la indicación. Hay una creatividad mínima ya que el modelo lucha por generar un contenido significativo.\n",
        "\n",
        "Cuarta Indicación: El texto generado comienza de manera coherente, pero se pierde la relevancia cuando pasa inesperadamente a describir un videojuego. La coherencia y la relevancia sufren en gran medida, y no hay creatividad ya que el modelo regurgita información existente."
      ],
      "metadata": {
        "id": "AQKlP8BwObTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Discuss how different prompts influence the direction of the story.**"
      ],
      "metadata": {
        "id": "L05VpJEUObTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar en los ejemplos anteriores, el modelo tiende a repetirse y a perder relevancia y coherencia cuando se le pide que continúe la historia sin un estímulo claro."
      ],
      "metadata": {
        "id": "Elr7EvnCObTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Experiment with custom prompts to generate different genres of creative content (e.g., horror, sci-fi, romance).**"
      ],
      "metadata": {
        "id": "AlQj2-o-ObTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una nueva historia en la cual se base en un contenido creativo en este caso va hacer de genero horror\n",
        "prompts = [\n",
        "    \"Under the full moon, in the silence of the night, a shadow lurked in the darkness,\",\n",
        "    \"The trees whispered secrets, and the wind carried a shiver with it,\",\n",
        "    \"In an abandoned house, footsteps echoed, though no living being was present.,\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(generate_creative_content(prompt))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T02:16:05.011768Z",
          "iopub.execute_input": "2023-08-24T02:16:05.012193Z",
          "iopub.status.idle": "2023-08-24T02:17:30.812794Z",
          "shell.execute_reply.started": "2023-08-24T02:16:05.012160Z",
          "shell.execute_reply": "2023-08-24T02:17:30.811493Z"
        },
        "trusted": true,
        "id": "HRJC5CG7ObTE",
        "outputId": "ac647c1b-6c00-4800-c06c-18ca7dee0af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Prompt: Under the full moon, in the silence of the night, a shadow lurked in the darkness,\n and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow was like a shadow upon the earth, and the moonlight was like a shadow upon the earth.\n\nThe shadow\n\n--------------------------------------------------\n\nPrompt: The trees whispered secrets, and the wind carried a shiver with it,\n and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered secrets, and the wind carried a shiver with it, and the sun was cold and cold, and the sky was black and black.\n\nThe trees whispered\n\n--------------------------------------------------\n\nPrompt: In an abandoned house, footsteps echoed, though no living being was present.,\n\n\nThe sound of a door opening and closing,\n\nThe sound of a door closing and opening,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing,\n\nThe sound of a door opening and closing\n\n--------------------------------------------------\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks:**"
      ],
      "metadata": {
        "id": "-9oUD93fObTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Use a larger GPT-2 variant (gpt2-large or gpt2-xl) and compare the quality of outputs**."
      ],
      "metadata": {
        "id": "_hAlV4ocObTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizar una variante más grande del modelo, solo se necesita cambiar el nombre del modelo a \"gpt2-large\" o \"gpt2-xl\". En este caso utilizare el GPT-large"
      ],
      "metadata": {
        "id": "XHTcp13mObTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_l = 'gpt2-large'\n",
        "model_l = GPT2LMHeadModel.from_pretrained(model_name_l)\n",
        "tokenizer_l = GPT2Tokenizer.from_pretrained(model_name_l)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T02:21:56.634124Z",
          "iopub.execute_input": "2023-08-24T02:21:56.634566Z",
          "iopub.status.idle": "2023-08-24T02:22:34.019464Z",
          "shell.execute_reply.started": "2023-08-24T02:21:56.634533Z",
          "shell.execute_reply": "2023-08-24T02:22:34.017566Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7dcdee34dd824023a708d05186f12c33",
            "957088fd057c4858b8e1925d4d359243",
            "59c17301164441e5802e5cf50807ba42",
            "3b3736a31bf94710a73aaf88131d60fb",
            "113b89bd60c4400eadd62e98b68597f7"
          ]
        },
        "id": "8lt5c7x0ObTF",
        "outputId": "8c7e3ee3-6147-4b0e-dd65-0948055bb878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dcdee34dd824023a708d05186f12c33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "957088fd057c4858b8e1925d4d359243"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59c17301164441e5802e5cf50807ba42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b3736a31bf94710a73aaf88131d60fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "113b89bd60c4400eadd62e98b68597f7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mantenemos la función para Generar Contenido Creativo de la parte del inicio de este ejercicio**"
      ],
      "metadata": {
        "id": "N0nvPK0UObTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_creative_content_l(prompt, max_length=150, temperature=1.0):\n",
        "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
        "\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer_l.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text\n",
        "    output = model_l.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    generated_text = tokenizer_l.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T02:24:13.950118Z",
          "iopub.execute_input": "2023-08-24T02:24:13.950711Z",
          "iopub.status.idle": "2023-08-24T02:24:13.959233Z",
          "shell.execute_reply.started": "2023-08-24T02:24:13.950669Z",
          "shell.execute_reply": "2023-08-24T02:24:13.958043Z"
        },
        "trusted": true,
        "id": "4zC4kyPUObTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Incorporate user feedback loops, where after getting an initial piece of text, they can provide a follow-up prompt to continue or steer the story.**"
      ],
      "metadata": {
        "id": "OEevX4_qObTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Once upon a time, in a kingdom far away,\",\n",
        "    \"In a dystopian future, where AI rules the world,\",\n",
        "    \"The last dinosaur on Earth was not like the others. It\",\n",
        "    \"Deep beneath the ocean waves, a secret civilization\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    user_feedback = \"\"\n",
        "    while not user_feedback.lower().startswith(\"exit\"):\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        generated = generate_creative_content_l(prompt)\n",
        "        print(generated)\n",
        "        user_feedback = input(\"Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt): \")\n",
        "        if user_feedback.lower() != \"exit\":\n",
        "            prompt += \" \" + user_feedback\n",
        "        print(\"-\" * 50)\n",
        "    print(\"=\" * 50)"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-08-24T02:25:33.719917Z",
          "iopub.execute_input": "2023-08-24T02:25:33.720366Z",
          "iopub.status.idle": "2023-08-24T02:33:52.808968Z",
          "shell.execute_reply.started": "2023-08-24T02:25:33.720330Z",
          "shell.execute_reply": "2023-08-24T02:33:52.807538Z"
        },
        "trusted": true,
        "id": "k44jdm3vObTF",
        "outputId": "84924ac9-5745-4301-e1ef-505d2fb76e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Prompt: Once upon a time, in a kingdom far away,\n the king and queen were blessed with a beautiful baby girl. Ever since that day, the princess has been growing up in a world of magic and adventure. But one day, the king and queen are kidnapped by a band of thieves. Now, the princess must find her way home and save her kingdom.\n\nThe game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda.\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt):   The princess was brave and beautiful\n"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------\nPrompt: Once upon a time, in a kingdom far away,  The princess was brave and beautiful\n, And the king was kind and gentle. But one day, the king was cruel and cold, And the princess was sad and alone. And the king was angry and cold, And the princess was sad and alone. And the king was cruel and cold, And the princess was sad and alone. And the king was cruel and cold, And the princess was sad and alone. And the king was cruel and cold, And the princess was sad and alone. And the king was cruel and cold, And the princess was sad and alone. And the king was cruel and cold, And the princess was sad and alone. And the king was cruel and cold,\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt):  exit\n"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------\n==================================================\nPrompt: In a dystopian future, where AI rules the world,\n the only way to survive is to become a super-soldier.\n\nThe game is set in a future where the world is ruled by a super-intelligence called the AI. The AI is a powerful and intelligent being that has been created by the government to protect the world from the threat of a super-intelligence.\n\nThe game is set in a dystopian future where the world is ruled by a super-intelligence called the AI. The AI is a powerful and intelligent being that has been created by the government to protect the world from the threat of a super-intelligence.\n\nThe game is set in a dystopian future where the world is ruled by a super-intelligence called the\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt):  A handsome and strong young man\n"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------\nPrompt: In a dystopian future, where AI rules the world, A handsome and strong young man\n named John is sent to a remote island to find a girl named Jane. But when he arrives, he finds that the island is a prison, and the only way to escape is to kill the guards.\n\nThe film is based on the novel by John Scalzi, and stars John Cusack, Jennifer Jason Leigh, and John Goodman.\n\nThe film is set to be released on October 10, 2017.\n\nSource: Variety\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt):  exit\n"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------\n==================================================\nPrompt: The last dinosaur on Earth was not like the others. It\n was a giant, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt):  While the wild animals of the forest.\n"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------\nPrompt: The last dinosaur on Earth was not like the others. It While the wild animals of the forest.\n The dinosaurs were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They were not like the other animals. They\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt):  exit\n"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------\n==================================================\nPrompt: Deep beneath the ocean waves, a secret civilization\n has been building a massive, underground city. The city is called the City of the Dead, and it is home to a mysterious race of undead. The city is a living, breathing, breathing city, and it is the only place in the world where the dead can live. The City of the Dead is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt):  exit\n"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------\n==================================================\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}