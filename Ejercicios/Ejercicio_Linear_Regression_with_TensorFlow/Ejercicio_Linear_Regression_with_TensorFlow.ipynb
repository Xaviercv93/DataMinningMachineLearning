{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#import tensorflow.compat.v1 as tf\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_5LOYlslMlY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el conjunto de datos\n",
        "raw = fetch_california_housing()\n",
        "X = pd.DataFrame(data=raw['data'], columns=raw['feature_names'])\n",
        "y = pd.Series(raw['target'])"
      ],
      "metadata": {
        "id": "z0jfYEKRpyfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar las características\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "UKOtv6tUp0Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kjztNun9p2BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Restablecer el grafo predeterminado\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "metadata": {
        "id": "yXhDF9dKp4zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Crear los tensores regulares para las características de entrada (X) y la variable objetivo (y)\n",
        "X_placeholder = tf.Variable(initial_value=X_train, dtype=tf.float32, name='X')\n",
        "y_placeholder = tf.Variable(initial_value=y_train, dtype=tf.float32, name='y')\n",
        "\n",
        "#X_placeholder = tf.placeholder(tf.float32, shape=[None, X_train.shape[1]])\n",
        "#y_placeholder = tf.placeholder(tf.float32, shape=[None])\n"
      ],
      "metadata": {
        "id": "1dlfQ-N-p8OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear las variables para los pesos (W) y el sesgo (b) del modelo\n",
        "#W = tf.Variable(tf.random.normal(shape=(X_train.shape[1],)), name='weights')\n",
        "#b = tf.Variable(0.0, name='bias')\n",
        "\n",
        "#W = tf.Variable(tf.random_normal_initializer([X_train.shape[1],1]))\n",
        "#b = tf.Variable(tf.random_normal_initializer(1))\n",
        "\n",
        "W = tf.Variable(tf.random.normal([X_train.shape[1], 1]))b = tf.Variable(tf.random.normal([1]))\n",
        "\n",
        "print(W.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnQH0rKep-RX",
        "outputId": "411ad0af-90c8-4f21-c060-3b0e08dc48a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.4736006 ]\n",
            " [ 1.3981395 ]\n",
            " [ 1.7650864 ]\n",
            " [-0.26746413]\n",
            " [-1.0863184 ]\n",
            " [ 0.3404211 ]\n",
            " [ 0.7825956 ]\n",
            " [-1.0403228 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir el modelo de regresión lineal: y_pred = X * W + b\n",
        "#y_pred = tf.add(tf.matmul(X_placeholder, tf.expand_dims(W, axis=1)), b, name='predictions')\n",
        "y_pred= tf.matmul(X_placeholder,W)+b"
      ],
      "metadata": {
        "id": "9mwMYKsMp__X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Definir la función de pérdida como el error cuadrático medio (MSE)\n",
        "#loss = tf.reduce_mean(tf.square(y_placeholder - y_pred), name='loss')\n",
        "loss = tf.reduce_mean(tf.square(y_pred - y_placeholder))"
      ],
      "metadata": {
        "id": "LVNc1XWfMvFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elegir un optimizador para minimizar la función de pérdida\n",
        "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
        "train_op = optimizer.minimize(loss)"
      ],
      "metadata": {
        "id": "pz_pGX3PMwk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size=32\n",
        "num_epochs=5"
      ],
      "metadata": {
        "id": "WQB92JphMyKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.compat.v1 import train\n",
        "\n",
        "#Initialize TensorFlow session.\n",
        "with tf.Session() as tfsession:\n",
        "  tfsession.run(tf.global_variables_initializer())\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    #barrido en cada epoca\n",
        "    for i in range(0, X_train.shape[0],batch_size):\n",
        "      #va desde el primer elemente o elemento 0 hasta batch_size\n",
        "      batch_X= X_train[i:i+batch_size]\n",
        "      batch_Y= Y_train[i:i+batch_size]\n",
        "      tfsession.run(train_op, feed_dict={X_placeholder:batch_X, y_placeholder:batch_Y})\n",
        "\n",
        "  if epoch % 100==0:\n",
        "    train_loss=tfsession.run()"
      ],
      "metadata": {
        "id": "QutVzAzhMzl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSYeltP9NBPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hou33wn2NOJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PfrXqzPENdyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "FBrvdUBrNfbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FFTHNc-wNhGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNlm88gnNsP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7KbUUU4MkEX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Definir el modelo de regresión lineal: y_pred = X * W + b\n",
        "y_pred = tf.add(tf.matmul(X_placeholder, tf.expand_dims(W, axis=1)), b, name='predictions')\n",
        "\n",
        "# Definir la función de pérdida como el error cuadrático medio (MSE)\n",
        "loss = tf.reduce_mean(tf.square(y_placeholder - y_pred), name='loss')\n",
        "\n",
        "# Elegir un optimizador para minimizar la función de pérdida\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train_op = optimizer.minimize(loss, name='train')\n",
        "\n",
        "# Inicializar la sesión de TensorFlow\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Configurar el número de épocas y la tasa de aprendizaje\n",
        "    num_epochs = 100\n",
        "    learning_rate = 0.01\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    for epoch in range(num_epochs):\n",
        "        _, epoch_loss = sess.run([train_op, loss], feed_dict={X_placeholder: X_train, y_placeholder: y_train})\n",
        "\n",
        "        # Imprimir la pérdida en intervalos regulares\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    test_loss = sess.run(loss, feed_dict={X_placeholder: X_test, y_placeholder: y_test})\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n"
      ]
    }
  ]
}