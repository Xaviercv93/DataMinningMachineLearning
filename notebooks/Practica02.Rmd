---
title: "Práctica 02"
output: github_document

---
# 2 Hands On: Data Quality and Pre-Processing
## 1. Assessing Data Quality
### Load the following packages: dplyr, na.tools, tidyimpute (version from github decisionpatterns/tidyimpute”)
```{r}
library(na.tools)
library(devtools)
library(dplyr)
library(tidyverse)
library(tidyimpute)
library(sos)
library(ggplot2)
```

### Load the carInsurance data set about the insurance risk rating of cars based on several characteristics of each car
```{r}
# Cargar el archivo de datos "carInsurance.Rdata"
load("../data/02_data/carInsurance.Rdata") 
carIns

# Asignar los datos cargados a la variable "carInsurance"
carInsurance <- carIns
head(carInsurance, 10)

# forma anterior
# #lee archivo csv, se indica que no contiene fila de encabezado
# data <- read.csv('../data/02_data/carInsurance.data', header=FALSE)
# 
# #reemplaza valores ? por NA
# data[data == "?"] <- NA
# 
# #crea un dataframe llamado carInsurance
# #se usa el objeto data como argumento para la funcion data.frame()
# carInsurance <- data.frame(data)
# 
# # vector de nombres de encabezado para el dataframe
# header <- c("symboling","normalizedLosses","make","fuelType","aspiration","nDoors","bodyStyle","driveWheels","engineLocation","wheelBase","length","width","height","curbWeight","engineType","nCylinders","engineSize","fuelSystem","bore","stroke","compression-ratio","horsepower","peakRpm","cityMpg","highwayMpg","price")
# 
# # Establecer el encabezado al dataframe
# names(carInsurance) <- header
# 
# 
# 
# # Imprimir el dataframe, solo 10 filas
# head(carInsurance, 10)



```
### (a) Check if there are any missing values.


```{r}
# Identificar columnas con valores faltantes
columnas_valores_faltantes <- colSums(is.na(carInsurance))>0
#head(columnas_valores_faltantes,10)
nombres_columnas_valores_faltantes <- names(columnas_valores_faltantes[columnas_valores_faltantes])
nombres_columnas_valores_faltantes

# Verificar si existen valores faltantes en el conjunto de datos
valores_faltantes <- any_na(carInsurance)

#valores_faltantes

# Imprimir mensaje dependiendo de la existencia de valores faltantes
if (valores_faltantes) {
  print("Faltan valores en el conjunto de datos.")
} else {
  print("No hay valores faltantes en el conjunto de datos.")
}
```
### (b) Count the number of cases that have, at least, one missing value
```{r}
# Contar el número de valores faltantes por columna
num_valores_faltantes <- carInsurance %>%
  filter_any_na() %>%
  count()

# Mostrar el tipo de datos de la variable num_valores_faltantes
typeof(num_valores_faltantes)

# Imprimir el número de valores faltantes por columna
print(num_valores_faltantes)

```
### (c) Create a new data set by removing all the cases that have missing values.
```{r}
# Calcular el recuento de filas en el conjunto de datos original
#count(carInsurance)

# Eliminar filas con valores faltantes
carInsurance_sin_NA <- drop_rows_any_na(carInsurance)

head(carInsurance_sin_NA,10)

# Calcular el recuento de filas en el conjunto de datos sin valores faltantes
#count(carInsurance_sin_NA)
```
### (d) Create a new data set by imputing all the missing values with 0.
```{r}

# Crear una copia del conjunto de datos original y reemplaza los valores NA por ceros, se aplica a todo el conjunto de datos
carInsuranceImpute <- carInsurance %>% impute_zero_all()

# Reemplazar los valores NA por ceros en todas las columnas
#carInsuranceImpute <- impute_zero_all(carInsuranceImpute)

head(carInsuranceImpute, 20)
#count(carInsuranceImpute)


```
### (e) Create a new data set by imputing the mean in all the columns which have double type values.

```{r}
# Identificar columnas con valores de tipo double
columnas_double <- sapply(carInsurance, is.double)

#nombre de las columnas_double
nombres_columnas_double <- names(columnas_double[columnas_double])
#nombres_columnas_double
#typeof(nombres_columnas_double)

# Calcular la media de cada columna
media <- colMeans(carInsurance[,nombres_columnas_double], na.rm = TRUE)
media

# Crear un nuevo conjunto de datos imputando la media en las columnas correspondientes
carInsuranceMean <- carInsurance

for (col in nombres_columnas_double) {
  carInsuranceMean[[col]][is.na(carInsuranceMean[[col]])] <- media[col]	
}

head(carInsurance[, sapply(carInsurance, is.double)])
head(carInsuranceMean[, sapply(carInsuranceMean, is.double)])
```

### (f) Create a new data set by imputing the mode in all the columns which have integer type values.

```{r}
library(modeest)

# Identificar las columnas con valores faltantes
columnas_valores_faltantes <- colSums(is.na(carInsuranceMean))>0
#head(columnas_valores_faltantes,10)
nombres_columnas_valores_faltantes <- names(columnas_valores_faltantes[columnas_valores_faltantes])
print(nombres_columnas_valores_faltantes)

# Verificar si existen valores faltantes en el conjunto de datos
valores_faltantes <- any_na(carInsuranceMean)
if (valores_faltantes) {
  print("Faltan valores en el conjunto de datos.")

} else {
  print("No hay valores faltantes en el conjunto de datos.")

}

# Identificar las columnas de tipo integer
columnas_integer <- sapply(carInsuranceMean, is.integer)
#nombres de las columnas integer
nombres_columnas_integer <- names(columnas_integer[columnas_integer])

# Función personalizada para calcular la moda de un vector
moda_personalizada <- function(x) {
  moda <- unique(x)[which.max(tabulate(match(x, unique(x))))]
  if (length(moda) == 0) {  # Si no hay moda, devolver NA
    return(NA)
  } else {
    return(moda)
  }
}


# Calcular la moda en las columnas de tipo integer
moda <- sapply(carInsuranceMean[, nombres_columnas_integer], moda_personalizada)
# Resultado: vector con las modas de cada columna
moda

# Crear un nuevo conjunto de datos imputando la moda en las columnas correspondientes
carInsuranceMode <- carInsuranceMean
for (col in nombres_columnas_integer) {
  valores_faltantes <- is.na(carInsuranceMode[[col]])
  carInsuranceMode[[col]][valores_faltantes] <- moda[col]
}

head(carInsuranceMode[, sapply(carInsuranceMode, is.integer)])

```


### (g) Create a new data set by imputing the most frequent value to the column ”nDoors”.
### Tip: use the function impute_replace()


```{r}


# Encontrar la moda de la variable nDoors en el conjunto de datos carInsuranceMode
nDoorsMode <- names(which.max(table(carInsuranceMode$nDoors)))
nDoorsMode

# Reemplazar los valores faltantes en la variable nDoors con la moda encontrada
carInsurancenDoorsMode <- carInsuranceMode %>%
  mutate(nDoors = impute_replace_all(nDoors, nDoorsMode))

head(carInsurancenDoorsMode)

```

### (h) Combine the three last imputations to obtain a final dataset. Are there any duplicated cases?
### Tip: use the functions distinct() and count()


```{r}
#imputar valores NA
carInsurancenDoorsModeImpute <- carInsurancenDoorsMode %>% impute_zero_all()



newCarInsuranceFInal <- carInsurancenDoorsModeImpute

# Verificar si existen casos duplicados
casosDuplicados <- newCarInsuranceFInal %>%
  distinct() %>%
  count()

# Imprimir el resultado
if (casosDuplicados$n == nrow(newCarInsuranceFInal)) {
  print("No hay casos duplicados en el conjunto de datos.")
} else {
  print("Existen casos duplicados en el conjunto de datos.")
}

# Verificar duplicados por columna
duplicadosPorColumna <- newCarInsuranceFInal %>%
  group_by(across(everything())) %>%
  count() %>%
  filter(n > 1) %>%
  select(-n)

# Imprimir el resultado
if (nrow(duplicadosPorColumna) == 0) {
  print("No hay columnas con duplicados en el conjunto de datos.")
} else {
  print("Columnas con duplicados y su conteo respectivo:")
  print(duplicadosPorColumna)
}

head(newCarInsuranceFInal,10)


```

## 2. Data Pre-Processing

### 2. Load the package dlookr. Use the same car insurance data set above and apply the following transformations to the price attribute. Be critical regarding the obtained results

```{r}
library(dlookr)


```

### (a) Apply range-based normalization and z-score normalization.
### Tip: use the function transform().


```{r}
# Realizar la normalización de la variable price utilizando los métodos de minmax y zscore
newCarInsuranceFInal %>%
   mutate(
     rangeNorm = transform(newCarInsuranceFInal$price, method = "minmax"),
   zScoreNorm = transform(newCarInsuranceFInal$price, method = "zscore")
   ) %>%
   select(rangeNorm, zScoreNorm) %>%
   head(20)

head(newCarInsuranceFInal,10)

```
### b) Discretize it into 4 equal-frequency ranges an into 4 equal-width ranges.
### Tip: use the function binning().
```{r}

library(dplyr)
library(binr)

# Realizar la transformación mediante el método de quantile y equal
newCarInsuranceFInal <- newCarInsuranceFInal %>%
  mutate(equalFrequency = binning(price, nbins = 4, type = "quantile"),
         equalWidth = binning(price, nbins = 4, type = "equal")) 
head(newCarInsuranceFInal,10)

# Imprimir los niveles de equalFrequency
cat("Niveles de equalFrequency: ", levels(newCarInsuranceFInal$equalFrequency), "\n")

# Imprimir los niveles de equalWidth
cat("Niveles de equalWidth: ", levels(newCarInsuranceFInal$equalWidth), "\n")

```
## 3. With the seed 111019 obtain the following samples on the car insurance data set.
### Tip: use the function sample_frac().
### (a) A random sample of 60% of the cases, with replacement
```{r}
# Establecer la semilla para la generación de números aleatorios
set.seed(111019)

# Obtener una muestra del 60% de los datos
sample_60_percent <- newCarInsuranceFInal %>%
  sample_frac(0.6, replace = TRUE)

# Imprimir las primeras filas de la muestra
head(sample_60_percent)

```

### (b) A stratified sample of 60% of the cases of cars, according to the fuelType attribute.
```{r}

set.seed(111019)  # Establece la semilla para reproducibilidad


# Calcula el tamaño de la muestra para cada categoría de fuelType
tamaños_muestra <- newCarInsuranceFInal %>%
  group_by(fuelType) %>%
  summarise(tamaño_muestra = round(n() * 0.6))

# Obtiene la muestra estratificada
muestra_estratificada <- newCarInsuranceFInal %>%
  inner_join(tamaños_muestra, by = "fuelType") %>%
  group_by(fuelType) %>%
  sample_frac(size = 0.6, replace = FALSE)

# Muestra los primeros casos de la muestra estratificada
head(muestra_estratificada)


```

### (c) Use the table() function to inspect the distribution of values in each of the two samples above
```{r}
# Obtener la tabla de frecuencias de la variable fuelType en la muestra del 60%
table(sample_60_percent$fuelType)

# Obtener la tabla de frecuencias de la variable fuelType en la muestra estratificada
table(muestra_estratificada$fuelType)



```
## 4. Load the package corrplot and select the numeric attributes of the car insurance data set.
### (a) Using the function cor(), obtain the pearson correlation coefficient between each pair of variables

```{r}
# Cargar el paquete corrplot
library(corrplot)

# Seleccionar las variables numéricas del conjunto de datos
numericVars <- newCarInsuranceFInal %>%
  select_if(is.numeric)

# Calcular la matriz de correlación de Pearson
corMatrix <- cor(numericVars, method = "pearson")

# Visualizar la matriz de correlación
corrplot(corMatrix, method = "color")



# otra forma de hacerlo
# Seleccionar las variables enteras del conjunto de datos
intnewCarInsuranceFInal <- newCarInsuranceFInal %>% 
    select_if(is.integer)

# Obtener los nombres de las columnas con variables enteras
colint <- newCarInsuranceFInal %>% 
    select_if(is.integer) %>%
    names()

# Calcular la matriz de correlación para las variables enteras
resMat <- cor(intnewCarInsuranceFInal)

# Visualizar la matriz de correlación usando el método 'AOE'
corrplot.mixed(resMat, order = 'AOE')

```

### (b) Apply the function cor.mtest() to the previous result to calculate the p-values and confidence intervals of the correlation coefficient for each pair of variables.
```{r}
# Calcular los p-valores y los intervalos de confianza para cada coeficiente de correlación
testRes = cor.mtest(numericVars, conf.level = 0.95)

# Visualizar la matriz de correlación con p-valores significativos
corrplot(corMatrix, p.mat = testRes$p, sig.level = 0.10,
         addCoef.col ='black', order = 'hclust', addrect = 2,tl.cex = 0.9, number.cex = 0.5)


```
### (c) Plot the all correlation information using the function corrplot. Explore some of its parameters.
```{r}
# Cargar el paquete corrplot
library(corrplot)



# Visualizar la matriz de correlación utilizando diferentes métodos
# Método: Números
corrplot(corMatrix, method = 'number', order = 'AOE', diag = FALSE,tl.cex = 0.9, number.cex = 0.5)
# Método: Círculos
corrplot(corMatrix, method = 'circle', order = 'AOE', diag = FALSE,tl.cex = 0.9, number.cex = 0.5)
# Método: Sombreado
corrplot(corMatrix, method = 'shade', order = 'AOE', diag = FALSE,tl.cex = 0.9, number.cex = 0.5)
# Método: Gráficos de pastel
corrplot(corMatrix, method = 'pie', order = 'AOE', diag = FALSE,tl.cex = 0.9, number.cex = 0.5)
# Método: Sombreado (parte inferior) y gráficos de pastel (parte superior)
corrplot(corMatrix, method = 'shade', order = 'AOE', type = 'lower', diag = FALSE,tl.cex = 0.9, number.cex = 0.5)
# Método mixto: Sombreado (parte inferior) y gráficos de pastel (parte superior)
corrplot.mixed(corMatrix, lower = 'shade', upper = 'pie', order = 'hclust',tl.cex = 0.9, number.cex = 0.5)


```

## 5. Load the data set USJudgeRatings, from the datasets package, containing lawyers’ ratings of state judges in the US Superior Court regarding a set of attributes.
### (a) Apply the function prcomp() to obtain the principal components. Inspect how each variable is obtained by the linear combination of each component.

```{r}
# Cargar el conjunto de datos USJudgeRatings
data(USJudgeRatings)

head(USJudgeRatings,10)

# Aplicar la función prcomp() para obtener los componentes principales
pca <- prcomp(USJudgeRatings)

# Inspeccionar cómo cada variable se obtiene mediante la combinación lineal de cada componente
var_weights <- pca$rotation

# Visualizar los pesos de cada variable en cada componente
print(var_weights)

```
### (b) Load the package ggbiplot and plot the two first components with the function ggbiplot(). You can label each point with the lawyer’s name by setting the labels parameter.
```{r}
# Cargar el paquete "ggbiplot"
library(plyr)
library(ggbiplot)

# Plotear los dos primeros componentes utilizando ggbiplot
ggbiplot(pca, labels = rownames(USJudgeRatings), obs.scale = 1, var.scale = 1)

```
