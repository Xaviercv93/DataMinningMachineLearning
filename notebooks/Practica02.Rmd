---
title: "Práctica 02"
output: github_document
---
# 2 Hands On: Data Quality and Pre-Processing
## 1. Assessing Data Quality
### Load the following packages: dplyr, na.tools, tidyimpute (version from github decisionpatterns/tidyimpute”)
```{r}
library(na.tools)
library(devtools)
library(dplyr)
library(tidyverse)
library(tidyimpute)
library(sos)
library(ggplot2)
```

### Load the carInsurance data set about the insurance risk rating of cars based on several characteristics of each car
```{r}
load("../data/02_data/carInsurance.Rdata") 
carIns
carInsurance <- carIns
head(carInsurance, 10)

# #lee archivo csv, se indica que no contiene fila de encabezado
# data <- read.csv('../data/02_data/carInsurance.data', header=FALSE)
# 
# #reemplaza valores ? por NA
# data[data == "?"] <- NA
# 
# #crea un dataframe llamado carInsurance
# #se usa el objeto data como argumento para la funcion data.frame()
# carInsurance <- data.frame(data)
# 
# # vector de nombres de encabezado para el dataframe
# header <- c("symboling","normalizedLosses","make","fuelType","aspiration","nDoors","bodyStyle","driveWheels","engineLocation","wheelBase","length","width","height","curbWeight","engineType","nCylinders","engineSize","fuelSystem","bore","stroke","compression-ratio","horsepower","peakRpm","cityMpg","highwayMpg","price")
# 
# # Establecer el encabezado al dataframe
# names(carInsurance) <- header
# 
# 
# 
# # Imprimir el dataframe, solo 10 filas
# head(carInsurance, 10)



```
### (a) Check if there are any missing values.


```{r}

columnas_valores_faltantes <- colSums(is.na(carInsurance))>0
#head(columnas_valores_faltantes,10)
nombres_columnas_valores_faltantes <- names(columnas_valores_faltantes[columnas_valores_faltantes])
nombres_columnas_valores_faltantes

valores_faltantes <- any_na(carInsurance)

#valores_faltantes

if (valores_faltantes) {
  print("Faltan valores en el conjunto de datos.")
} else {
  print("No hay valores faltantes en el conjunto de datos.")
}
```
### (b) Count the number of cases that have, at least, one missing value
```{r}
num_valores_faltantes <- carInsurance %>%
  filter_any_na() %>%
  count()
typeof(num_valores_faltantes)
print(num_valores_faltantes)

```
### (c) Create a new data set by removing all the cases that have missing values.
```{r}
#head(carInsurance,10)
#count(carInsurance)
carInsurance_sin_NA <- drop_rows_any_na(carInsurance)
head(carInsurance_sin_NA,10)
#count(carInsurance_sin_NA)
```
### (d) Create a new data set by imputing all the missing values with 0.
```{r}

# Crear una copia del conjunto de datos original y reemplaza los valores NA por ceros, se aplica a todo el conjunto de datos
carInsuranceImpute <- carInsurance %>% impute_zero_all()

# Reemplazar los valores NA por ceros en todas las columnas
#carInsuranceImpute <- impute_zero_all(carInsuranceImpute)

head(carInsuranceImpute, 20)
#count(carInsuranceImpute)


```
### (e) Create a new data set by imputing the mean in all the columns which have double type values.

```{r}



# Identificar columnas con valores de tipo double
columnas_double <- sapply(carInsurance, is.double)

#nombre de las columnas_double
nombres_columnas_double <- names(columnas_double[columnas_double])
#nombres_columnas_double
#typeof(nombres_columnas_double)

# Calcular la media de cada columna
media <- colMeans(carInsurance[,nombres_columnas_double], na.rm = TRUE)
media

# Crear un nuevo conjunto de datos imputando la media en las columnas correspondientes
carInsuranceMean <- carInsurance

for (col in nombres_columnas_double) {
  carInsuranceMean[[col]][is.na(carInsuranceMean[[col]])] <- media[col]	
}
head(carInsurance[, sapply(carInsurance, is.double)])
head(carInsuranceMean[, sapply(carInsuranceMean, is.double)])


```

### (f) Create a new data set by imputing the mode in all the columns which have integer type values.

```{r}
# Cargar el paquete necesario
library(modeest)



columnas_valores_faltantes <- colSums(is.na(carInsuranceMean))>0
#head(columnas_valores_faltantes,10)
nombres_columnas_valores_faltantes <- names(columnas_valores_faltantes[columnas_valores_faltantes])
print(nombres_columnas_valores_faltantes)


valores_faltantes <- any_na(carInsuranceMean)

#valores_faltantes

if (valores_faltantes) {
  print("Faltan valores en el conjunto de datos.")

} else {
  print("No hay valores faltantes en el conjunto de datos.")

}









#identificar columnas int
columnas_integer <- sapply(carInsuranceMean, is.integer)

#print(columnas_integer)




#nombres de las columnas int
nombres_columnas_integer <- names(columnas_integer[columnas_integer])
#nombres_columnas_integer


# Crear una función personalizada para calcular la moda de un vector
moda_personalizada <- function(x) {
  moda <- unique(x)[which.max(tabulate(match(x, unique(x))))]
  if (length(moda) == 0) {  # Si no hay moda, devolver NA
    return(NA)
  } else {
    return(moda)
  }
}


# Calcular la moda en las columnas de tipo double
moda <- sapply(carInsuranceMean[, nombres_columnas_integer], moda_personalizada)

# Resultado: vector con las modas de cada columna
moda
# Crear un nuevo conjunto de datos imputando la moda en las columnas correspondientes
carInsuranceMode <- carInsuranceMean

for (col in nombres_columnas_integer) {
  valores_faltantes <- is.na(carInsuranceMode[[col]])
  carInsuranceMode[[col]][valores_faltantes] <- moda[col]
}

head(carInsuranceMode[, sapply(carInsuranceMode, is.integer)])

```


### (g) Create a new data set by imputing the most frequent value to the column ”nDoors”.
### Tip: use the function impute_replace()


```{r}



nDoorsMode <- names(which.max(table(carInsuranceMode$nDoors)))
nDoorsMode

carInsurancenDoorsMode <- carInsuranceMode %>%
  mutate(nDoors = impute_replace_all(nDoors, nDoorsMode))
head(carInsurancenDoorsMode)

```

### (h) Combine the three last imputations to obtain a final dataset. Are there any duplicated cases?
### Tip: use the functions distinct() and count()


```{r}
#imputar valores NA
carInsurancenDoorsModeImpute <- carInsurancenDoorsMode %>% impute_zero_all()



newCarInsuranceFInal <- carInsurancenDoorsModeImpute

# Verificar si existen casos duplicados
casosDuplicados <- newCarInsuranceFInal %>%
  distinct() %>%
  count()

# Imprimir el resultado
if (casosDuplicados$n == nrow(newCarInsuranceFInal)) {
  print("No hay casos duplicados en el conjunto de datos.")
} else {
  print("Existen casos duplicados en el conjunto de datos.")
}

# Verificar duplicados por columna
duplicadosPorColumna <- newCarInsuranceFInal %>%
  group_by(across(everything())) %>%
  count() %>%
  filter(n > 1) %>%
  select(-n)

# Imprimir el resultado
if (nrow(duplicadosPorColumna) == 0) {
  print("No hay columnas con duplicados en el conjunto de datos.")
} else {
  print("Columnas con duplicados y su conteo respectivo:")
  print(duplicadosPorColumna)
}

head(newCarInsuranceFInal,10)


```

## 2. Data Pre-Processing

### 2. Load the package dlookr. Use the same car insurance data set above and apply the following transformations to the price attribute. Be critical regarding the obtained results

```{r}
library(dlookr)


```

### (a) Apply range-based normalization and z-score normalization.
### Tip: use the function transform().


```{r}

newCarInsuranceFInal %>%
   mutate(
     rangeNorm = transform(newCarInsuranceFInal$price, method = "minmax"),
   zScoreNorm = transform(newCarInsuranceFInal$price, method = "zscore")
   ) %>%
   select(rangeNorm, zScoreNorm) %>%
   head(20)

head(newCarInsuranceFInal,10)

```
### b) Discretize it into 4 equal-frequency ranges an into 4 equal-width ranges.
### Tip: use the function binning().
```{r}

library(dplyr)
library(binr)

newCarInsuranceFInal <- newCarInsuranceFInal %>%
  mutate(equalFrequency = binning(price, nbins = 4, type = "quantile"),
         equalWidth = binning(price, nbins = 4, type = "equal")) 
head(newCarInsuranceFInal,10)

# Imprimir los niveles de equalFrequency
cat("Niveles de equalFrequency: ", levels(newCarInsuranceFInal$equalFrequency), "\n")

# Imprimir los niveles de equalWidth
cat("Niveles de equalWidth: ", levels(newCarInsuranceFInal$equalWidth), "\n")

```
## 3. With the seed 111019 obtain the following samples on the car insurance data set.
### Tip: use the function sample_frac().
### (a) A random sample of 60% of the cases, with replacement
```{r}
set.seed(111019)

sample_60_percent <- newCarInsuranceFInal %>%
  sample_frac(0.6, replace = TRUE)

head(sample_60_percent)

```

### (b) A stratified sample of 60% of the cases of cars, according to the fuelType attribute.
```{r}

set.seed(111019)  # Establece la semilla para reproducibilidad


# Calcula el tamaño de la muestra para cada categoría de fuelType
tamaños_muestra <- newCarInsuranceFInal %>%
  group_by(fuelType) %>%
  summarise(tamaño_muestra = round(n() * 0.6))

# Obtiene la muestra estratificada
muestra_estratificada <- newCarInsuranceFInal %>%
  inner_join(tamaños_muestra, by = "fuelType") %>%
  group_by(fuelType) %>%
  sample_frac(size = 0.6, replace = FALSE)

# Muestra los primeros casos de la muestra estratificada
head(muestra_estratificada)


```

### (c) Use the table() function to inspect the distribution of values in each of the two samples above
```{r}

table(sample_60_percent$fuelType)


table(muestra_estratificada$fuelType)



```
## 4. Load the package corrplot and select the numeric attributes of the car insurance data set.
### (a) Using the function cor(), obtain the pearson correlation coefficient between each pair of variables

```{r}
# Cargar el paquete corrplot
library(corrplot)

# Seleccionar las variables numéricas del conjunto de datos
numericVars <- newCarInsuranceFInal %>%
  select_if(is.numeric)

# Calcular la matriz de correlación de Pearson
corMatrix <- cor(numericVars, method = "pearson")



# Visualizar la matriz de correlación
corrplot(corMatrix, method = "color")






```
